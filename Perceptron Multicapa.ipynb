{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/B-Lina/FundamentosRedesNeuronales/blob/main/Perceptron%20Multicapa.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jjx2qZZxA0bh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c617f79-40e5-4d15-9697-b0aefbe23358"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoca 50 Error min = 0.5040246700696793\n",
            "Epoca 100 Error min = 0.5008655916152744\n",
            "Epoca 150 Error min = 0.49987931310107936\n",
            "Epoca 200 Error min = 0.4991423606759069\n",
            "Epoca 250 Error min = 0.49827955753111697\n",
            "Epoca 300 Error min = 0.49708946005891885\n",
            "Epoca 350 Error min = 0.4953275189365731\n",
            "Epoca 400 Error min = 0.4926215559462014\n",
            "Epoca 450 Error min = 0.4883723859261856\n",
            "Epoca 500 Error min = 0.48160419861391623\n",
            "Epoca 550 Error min = 0.47080754254031965\n",
            "Epoca 600 Error min = 0.45406013686264046\n",
            "Epoca 650 Error min = 0.4300078499437255\n",
            "Epoca 700 Error min = 0.39937445198464827\n",
            "Epoca 750 Error min = 0.36440130052400577\n",
            "Epoca 800 Error min = 0.32554717602058747\n",
            "Epoca 850 Error min = 0.27997610665793127\n",
            "Epoca 900 Error min = 0.22684903747699564\n",
            "Epoca 950 Error min = 0.1737967739945941\n",
            "Epoca 1000 Error min = 0.130062826508774\n",
            "Epoca 1050 Error min = 0.09811990569295831\n",
            "Epoca 1100 Error min = 0.0758062254884453\n",
            "Epoca 1150 Error min = 0.06022109626097498\n",
            "Epoca 1200 Error min = 0.04912074538421752\n",
            "Epoca 1250 Error min = 0.04100560277588264\n",
            "Epoca 1300 Error min = 0.03491249734359986\n",
            "Epoca 1350 Error min = 0.030222473933478964\n",
            "Epoca 1400 Error min = 0.02653109656390109\n",
            "Epoca 1450 Error min = 0.02356805457577208\n",
            "Epoca 1500 Error min = 0.021148286709560902\n",
            "Epoca 1550 Error min = 0.0191420909968663\n",
            "Epoca 1600 Error min = 0.01745654317397615\n",
            "Epoca 1650 Error min = 0.016023705663316536\n",
            "Epoca 1700 Error min = 0.014792981598547517\n",
            "Epoca 1750 Error min = 0.013726049462231096\n",
            "Epoca 1800 Error min = 0.012793437945630924\n",
            "Epoca 1850 Error min = 0.011972164888849562\n",
            "Epoca 1900 Error min = 0.011244080257306659\n",
            "Epoca 1950 Error min = 0.010594683697393715\n",
            "Epoca 2000 Error min = 0.010012267642639272\n",
            "Pesos finales capa entrada:\n",
            " [[ 2.74237474 -1.8716918   0.70513537]\n",
            " [-2.52547675 -2.3316564   0.51075624]\n",
            " [-1.10288484  2.57070231 -0.00781571]]\n",
            "Pesos finales capa oculta:\n",
            " [-3.07514578 -3.17130409 -3.06020415]\n",
            "Predicciones de la red entrenada:\n",
            "\n",
            "Entrada: [0 1 1] -> Salida predicha: 0.925 -> Salida esperada: 1 -> Clasificación: 1\n",
            "Entrada: [1 0 1] -> Salida predicha: 0.921 -> Salida esperada: 1 -> Clasificación: 1\n",
            "Entrada: [0 0 1] -> Salida predicha: 0.034 -> Salida esperada: 0 -> Clasificación: 0\n",
            "Entrada: [1 1 1] -> Salida predicha: 0.083 -> Salida esperada: 0 -> Clasificación: 0\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Implemente un perceptron multicapa y utilíselo para aprender los siguientes problemas:\n",
        "# 1) Función lógica ’O exclusivo’ con entradas\n",
        "# x = {{-1, 1}, {1, -1}, {-1, -1}, {1, 1}},\n",
        "# y salida esperada y = {1, 1, -1, -1}.\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "pesosCapaEntrada = np.random.uniform(-0.5, 0.5, (3, 3))\n",
        "\n",
        "pesosCapaOculta = np.random.uniform(-0.5, 0.5, 3)\n",
        "\n",
        "entrada = np.array([[0,1,1], [1,0,1], [0,0,1], [1,1,1]])\n",
        "\n",
        "salida = np.array([1, 1, 0, 0])\n",
        "\n",
        "def CalcularError(salida, oTotal):\n",
        "  error = 0.5 * np.sum((salida - oTotal) ** 2)\n",
        "  return error\n",
        "\n",
        "def funcionTanh(h):\n",
        "    return np.tanh(h)\n",
        "\n",
        "def tanhDerivada(h):\n",
        "    return 1 - np.tanh(h) ** 2\n",
        "\n",
        "def funcionSigmoid(h):\n",
        "    return 1 / (1 + np.exp(-h))\n",
        "\n",
        "def sigmoid_deriv(h):\n",
        "    s = funcionSigmoid(h)\n",
        "    return s * (1 - s)\n",
        "\n",
        "def perceptronMulticapa(tasaAprendizaje, pesosCapaEntrada, pesosCapaOculta, entrada, salida):\n",
        "\n",
        "  epoca = 0\n",
        "  error = 1\n",
        "  error_min = 10\n",
        "  w_minEntrada = pesosCapaEntrada.copy()\n",
        "  w_minOculta = pesosCapaOculta.copy()\n",
        "\n",
        "  while error > 0.01 and epoca < (3000):\n",
        "\n",
        "    salidaFinal = np.zeros(len(entrada))\n",
        "    salidaTotalCapaOculta = np.zeros((len(entrada), len(pesosCapaEntrada)))\n",
        "\n",
        "    for i in range (len(entrada)):\n",
        "\n",
        "      salidaCapaOculta = np.zeros(len(pesosCapaEntrada))\n",
        "\n",
        "      for j in range (len(pesosCapaEntrada)):\n",
        "\n",
        "        exitacionCapaEntrada = entrada[i] @ pesosCapaEntrada[j]\n",
        "        salidaCapaOculta[j] = funcionTanh(exitacionCapaEntrada)\n",
        "\n",
        "      salidaTotalCapaOculta[i] = salidaCapaOculta\n",
        "      exitacionSalida = salidaCapaOculta @ pesosCapaOculta\n",
        "      salidaFinal[i] = funcionSigmoid(exitacionSalida)\n",
        "\n",
        "    error = CalcularError(salida, salidaFinal)\n",
        "\n",
        "    for i in range(len(entrada)):\n",
        "\n",
        "      exitacionSalida = salidaTotalCapaOculta[i] @ pesosCapaOculta\n",
        "      deltaSalida = (salida[i] - salidaFinal[i]) * sigmoid_deriv(exitacionSalida)\n",
        "\n",
        "      pesosCapaOculta += tasaAprendizaje * salidaTotalCapaOculta[i] * deltaSalida\n",
        "\n",
        "      for j in range(len(pesosCapaEntrada)):\n",
        "        exitacionCapaEntrada = entrada[i] @ pesosCapaEntrada[j]\n",
        "        deltaOculta = tanhDerivada(exitacionCapaEntrada) * (pesosCapaOculta[j] * deltaSalida)\n",
        "        pesosCapaEntrada[j] += tasaAprendizaje * entrada[i] * deltaOculta\n",
        "\n",
        "    if error < error_min:\n",
        "      error_min = error\n",
        "      w_minEntrada = pesosCapaEntrada.copy()\n",
        "      w_minOculta = pesosCapaOculta.copy()\n",
        "\n",
        "    epoca = epoca+ 1\n",
        "    if epoca % 50 == 0:\n",
        "      print(\"Epoca\", epoca, \"Error min =\", error_min)\n",
        "\n",
        "\n",
        "  print(\"Pesos finales capa entrada:\\n\", w_minEntrada)\n",
        "  print(\"Pesos finales capa oculta:\\n\", w_minOculta)\n",
        "  return w_minEntrada, w_minOculta\n",
        "\n",
        "def pruebaPerceptronMulticapa(tasaAprendizaje, pesosCapaEntrada, pesosCapaOculta, entrada, salida):\n",
        "\n",
        "  w_entrada, w_oculta = perceptronMulticapa(tasaAprendizaje, pesosCapaEntrada, pesosCapaOculta, entrada, salida)\n",
        "\n",
        "  print(\"Predicciones de la red entrenada:\\n\")\n",
        "\n",
        "  for i in range(len(entrada)):\n",
        "\n",
        "      salidaCapaOculta = np.zeros(len(w_entrada))\n",
        "\n",
        "      for j in range(len(w_entrada)):\n",
        "\n",
        "        salidaCapaOculta[j] = funcionTanh(np.dot(entrada[i], w_entrada[j]))\n",
        "\n",
        "\n",
        "      salidaFinal = funcionSigmoid(np.dot(salidaCapaOculta, w_oculta))\n",
        "\n",
        "\n",
        "      salidaRedondeada = int(round(salidaFinal))\n",
        "\n",
        "      print(f\"Entrada: {entrada[i]} -> Salida predicha: {salidaFinal:.3f} -> Salida esperada: {salida[i]} -> Clasificación: {salidaRedondeada}\")\n",
        "\n",
        "pruebaPerceptronMulticapa(0.1, pesosCapaEntrada, pesosCapaOculta, entrada, salida)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2) Discriminar si un número es par, con entradas dadas por el conjunto de números\n",
        "# decimales del 0 al 9 (usar archivo TP2-ej3-mapa-de-pixeles-digitos-decimales.txt)\n",
        "# epresentados por imágenes de 5 x 7 pixeles.\n",
        "# Entrene con un subconjunto de los dígitos y utilice el resto para testear a la red. ¿Qué podría\n",
        "# decir acerca de la capacidad para generalizar de la red?\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "with open(\"EntradasEntrenamientoMulticapa.txt\", \"r\") as f:\n",
        "    lineasEntrenamiento = f.readlines()\n",
        "\n",
        "with open(\"EntradasPruebaMulticapa.txt\", \"r\") as f:\n",
        "    lineasPrueba = f.readlines()\n",
        "\n",
        "\n",
        "datosEntrenamiento = []\n",
        "for linea in lineasEntrenamiento:\n",
        "    fila = [int(x) for x in linea.strip().split()]\n",
        "    datosEntrenamiento.extend(fila)\n",
        "\n",
        "datosPrueba = []\n",
        "for linea in lineasPrueba:\n",
        "    fila = [int(x) for x in linea.strip().split()]\n",
        "    datosPrueba.extend(fila)\n",
        "\n",
        "arraysEntrenamiento = [np.array(datosEntrenamiento[i:i+35]) for i in range(0, len(datosEntrenamiento), 35)]\n",
        "\n",
        "arraysPrueba = [np.array(datosPrueba[i:i+35]) for i in range(0, len(datosPrueba), 35)]\n",
        "\n",
        "pesosCapaEntrada = np.random.uniform(-0.5, 0.5, (30, 35))\n",
        "\n",
        "pesosCapaOculta = np.random.uniform(-0.5, 0.5, 30)\n",
        "\n",
        "entrada = arraysEntrenamiento\n",
        "\n",
        "salidaEntrenamiento = np.array([0, 1, 0, 1, 0, 1, 0, 1])\n",
        "\n",
        "salidaPrueba = ([0, 1])\n",
        "\n",
        "def CalcularError(salidaEntrenamiento, oTotal):\n",
        "  error = 0.5 * np.sum((salidaEntrenamiento - oTotal) ** 2)\n",
        "  return error\n",
        "\n",
        "def funcionTanh(h):\n",
        "    return np.tanh(h)\n",
        "\n",
        "def tanhDerivada(h):\n",
        "    return 1 - np.tanh(h) ** 2\n",
        "\n",
        "def funcionSigmoid(h):\n",
        "    return 1 / (1 + np.exp(-h))\n",
        "\n",
        "def sigmoid_deriv(h):\n",
        "    s = funcionSigmoid(h)\n",
        "    return s * (1 - s)\n",
        "\n",
        "def perceptronMulticapa(tasaAprendizaje, pesosCapaEntrada, pesosCapaOculta, entrada, salidaEntrenamiento):\n",
        "\n",
        "  epoca = 0\n",
        "  error = 1\n",
        "  error_min = 10\n",
        "  w_minEntrada = pesosCapaEntrada.copy()\n",
        "  w_minOculta = pesosCapaOculta.copy()\n",
        "\n",
        "  while error > 0.00001 and epoca < (3000):\n",
        "\n",
        "    salidaFinal = np.zeros(len(entrada))\n",
        "    salidaTotalCapaOculta = np.zeros((len(entrada), len(pesosCapaEntrada)))\n",
        "\n",
        "    for i in range (len(entrada)):\n",
        "\n",
        "      salidaCapaOculta = np.zeros(len(pesosCapaEntrada))\n",
        "\n",
        "      for j in range (len(pesosCapaEntrada)):\n",
        "\n",
        "        exitacionCapaEntrada = entrada[i] @ pesosCapaEntrada[j]\n",
        "        salidaCapaOculta[j] = funcionTanh(exitacionCapaEntrada)\n",
        "\n",
        "      salidaTotalCapaOculta[i] = salidaCapaOculta\n",
        "      exitacionSalida = salidaCapaOculta @ pesosCapaOculta\n",
        "      salidaFinal[i] = funcionSigmoid(exitacionSalida)\n",
        "\n",
        "\n",
        "    error = CalcularError(salidaEntrenamiento, salidaFinal)\n",
        "\n",
        "    for i in range(len(entrada)):\n",
        "\n",
        "      exitacionSalida = salidaTotalCapaOculta[i] @ pesosCapaOculta\n",
        "      deltaSalida = (salidaEntrenamiento[i] - salidaFinal[i]) * sigmoid_deriv(exitacionSalida)\n",
        "\n",
        "      pesosCapaOculta += tasaAprendizaje * salidaTotalCapaOculta[i] * deltaSalida\n",
        "\n",
        "      for j in range(len(pesosCapaEntrada)):\n",
        "        exitacionCapaEntrada = entrada[i] @ pesosCapaEntrada[j]\n",
        "        deltaOculta = tanhDerivada(exitacionCapaEntrada) * (pesosCapaOculta[j] * deltaSalida)\n",
        "        pesosCapaEntrada[j] += tasaAprendizaje * entrada[i] * deltaOculta\n",
        "\n",
        "    if error < error_min:\n",
        "      error_min = error\n",
        "      w_minEntrada = pesosCapaEntrada.copy()\n",
        "      w_minOculta = pesosCapaOculta.copy()\n",
        "\n",
        "    epoca = epoca+ 1\n",
        "    if epoca % 100 == 0:\n",
        "      print(\"Epoca\", epoca, \"Error min =\", error_min)\n",
        "\n",
        "\n",
        "  print(\"Pesos finales capa entrada:\\n\", w_minEntrada)\n",
        "  print(\"Pesos finales capa oculta:\\n\", w_minOculta)\n",
        "  return w_minEntrada, w_minOculta\n",
        "\n",
        "\n",
        "\n",
        "def perceptronMuticapaPrueba(tasaAprendizaje, pesosCapaEntrada, pesosCapaOculta, entrada, salidaEntrenamiento):\n",
        "\n",
        "    pesosCapaEntrada, pesosCapaOculta = perceptronMulticapa(tasaAprendizaje, pesosCapaEntrada, pesosCapaOculta, entrada, salidaEntrenamiento)\n",
        "\n",
        "    entradaPrueba = arraysPrueba\n",
        "\n",
        "    for i, entradaIndividual in enumerate(entradaPrueba):\n",
        "\n",
        "        salidaCapaOculta = funcionTanh(np.dot(pesosCapaEntrada, entradaIndividual))\n",
        "\n",
        "        salidaFinal = funcionSigmoid(np.dot(pesosCapaOculta, salidaCapaOculta))\n",
        "\n",
        "        salidaBinaria = 1 if salidaFinal >= 0.5 else 0\n",
        "\n",
        "        print(f\"Entrada {i+1}: salida de la red = {salidaFinal} → esperada = {salidaPrueba[i]} → binaria = {salidaBinaria}\")\n",
        "\n",
        "perceptronMuticapaPrueba(0.1, pesosCapaEntrada, pesosCapaOculta, entrada, salidaEntrenamiento)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "movmJOQ8IAT-",
        "outputId": "0efaca8e-2650-437e-a3dc-70a9ac0388a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoca 100 Error min = 0.015188414211819488\n",
            "Epoca 200 Error min = 0.005684485056737636\n",
            "Epoca 300 Error min = 0.003322196037096004\n",
            "Epoca 400 Error min = 0.0022990765093336783\n",
            "Epoca 500 Error min = 0.0017387612751085643\n",
            "Epoca 600 Error min = 0.001388831300423111\n",
            "Epoca 700 Error min = 0.0011510783241433522\n",
            "Epoca 800 Error min = 0.0009797716481407047\n",
            "Epoca 900 Error min = 0.000850881126082923\n",
            "Epoca 1000 Error min = 0.0007506276237051885\n",
            "Epoca 1100 Error min = 0.0006705693116122048\n",
            "Epoca 1200 Error min = 0.0006052582507436998\n",
            "Epoca 1300 Error min = 0.0005510279579847726\n",
            "Epoca 1400 Error min = 0.0005053240315443632\n",
            "Epoca 1500 Error min = 0.0004663144505531574\n",
            "Epoca 1600 Error min = 0.00043265243437055467\n",
            "Epoca 1700 Error min = 0.0004033266278101141\n",
            "Epoca 1800 Error min = 0.000377563361512071\n",
            "Epoca 1900 Error min = 0.000354761081107403\n",
            "Epoca 2000 Error min = 0.000334445267962152\n",
            "Epoca 2100 Error min = 0.0003162367701854191\n",
            "Epoca 2200 Error min = 0.00029982912208588496\n",
            "Epoca 2300 Error min = 0.00028497201823206\n",
            "Epoca 2400 Error min = 0.00027145908325745523\n",
            "Epoca 2500 Error min = 0.00025911869232352085\n",
            "Epoca 2600 Error min = 0.00024780699233523535\n",
            "Epoca 2700 Error min = 0.00023740253369237876\n",
            "Epoca 2800 Error min = 0.00022780209620995728\n",
            "Epoca 2900 Error min = 0.000218917411222463\n",
            "Epoca 3000 Error min = 0.00021067256376350953\n",
            "Pesos finales capa entrada:\n",
            " [[-0.11528452  0.1327968   0.14507829 ...  0.2033612  -0.21377468\n",
            "  -0.48475072]\n",
            " [-0.1233784   0.03558728  0.18837572 ... -0.17236851 -0.05220858\n",
            "   0.134705  ]\n",
            " [ 0.40172514  0.28302759  0.03741876 ... -0.03300446  0.41662676\n",
            "   0.03495602]\n",
            " ...\n",
            " [-0.39797046 -0.263875   -0.53448877 ...  0.04936769  0.48624292\n",
            "  -0.26724702]\n",
            " [-0.02509709 -0.43689532  0.26814597 ...  0.03561705  0.17599815\n",
            "   0.3240391 ]\n",
            " [-0.33670233  0.34389196  0.16116706 ... -0.16675772  0.04293498\n",
            "  -0.06887977]]\n",
            "Pesos finales capa oculta:\n",
            " [ 1.56126698 -0.23185845  0.28261087  0.35499293  0.4050533   1.06426395\n",
            " -0.15285162 -0.88250473 -0.35838935  0.13445483 -0.36736177  0.19466447\n",
            " -0.17099177 -0.41063757  0.6148262  -0.34283917  0.30605638 -0.08854986\n",
            " -0.04271395  0.15002921  0.13002621  0.59495899 -1.05063371 -0.16801914\n",
            "  0.90956947 -0.02466305 -0.49652379 -0.63436112 -0.09769601  0.86944868]\n",
            "Entrada 1: salida de la red = 0.5672898136440075 → esperada = 0 → binaria = 1\n",
            "Entrada 2: salida de la red = 0.7380312016160001 → esperada = 1 → binaria = 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Una vez que la red haya aprendido, use patrones de entrada correspondientes a los dígitos\n",
        "# de entrenamiento pero con sus píxeles afectados por ruido (por ejemplo, con probabilidad\n",
        "# 0,02, intercambie el valor de los bits en la imagen del dígito) y evalúe los resultados.\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "with open(\"/EntradasTotalesMulticapa.txt\", \"r\") as f:\n",
        "    lineas = f.readlines()\n",
        "\n",
        "datos = []\n",
        "for linea in lineas:\n",
        "    fila = [int(x) for x in linea.strip().split()]\n",
        "    datos.extend(fila)\n",
        "\n",
        "arrays = [np.array(datos[i:i+35]) for i in range(0, len(datos), 35)]\n",
        "\n",
        "pesosCapaEntrada = np.random.uniform(-0.5, 0.5, (30, 35))\n",
        "\n",
        "pesosCapaOculta = np.random.uniform(-0.5, 0.5, (10, 30))\n",
        "\n",
        "entrada = arrays\n",
        "\n",
        "salida = np.eye(10)\n",
        "\n",
        "def CalcularError(salida, oTotal):\n",
        "  error = 0.5 * np.sum((salida - oTotal) ** 2)\n",
        "  return error\n",
        "\n",
        "def funcionTanh(h):\n",
        "    return np.tanh(h)\n",
        "\n",
        "def tanhDerivada(h):\n",
        "    return 1 - np.tanh(h) ** 2\n",
        "\n",
        "def funcionSigmoid(h):\n",
        "    return 1 / (1 + np.exp(-h))\n",
        "\n",
        "def sigmoid_deriv(h):\n",
        "    s = funcionSigmoid(h)\n",
        "    return s * (1 - s)\n",
        "\n",
        "def perceptronMulticapa(tasaAprendizaje, pesosCapaEntrada, pesosCapaOculta, entrada, salida):\n",
        "\n",
        "  epoca = 0\n",
        "  error = 1\n",
        "  error_min = 10\n",
        "  w_minEntrada = pesosCapaEntrada.copy()\n",
        "  w_minOculta = pesosCapaOculta.copy()\n",
        "\n",
        "  while error > 0.00001 and epoca < (3000):\n",
        "\n",
        "    salidaFinal = np.zeros((len(entrada), 10))\n",
        "    salidaTotalCapaOculta = np.zeros((len(entrada), len(pesosCapaEntrada)))\n",
        "\n",
        "    for i in range (len(entrada)):\n",
        "\n",
        "      salidaCapaOculta = np.zeros(len(pesosCapaEntrada))\n",
        "\n",
        "      for j in range (len(pesosCapaEntrada)):\n",
        "\n",
        "        exitacionCapaEntrada = entrada[i] @ pesosCapaEntrada[j]\n",
        "        salidaCapaOculta[j] = funcionTanh(exitacionCapaEntrada)\n",
        "\n",
        "      salidaTotalCapaOculta[i] = salidaCapaOculta\n",
        "      exitacionSalida = pesosCapaOculta @ salidaCapaOculta\n",
        "      salidaFinal[i] = funcionSigmoid(exitacionSalida)\n",
        "\n",
        "    error = CalcularError(salida, salidaFinal)\n",
        "\n",
        "    for i in range(len(entrada)):\n",
        "\n",
        "      exitacionSalida = pesosCapaOculta @ salidaTotalCapaOculta[i]\n",
        "      deltaSalida = (salida[i] - salidaFinal[i]) * sigmoid_deriv(exitacionSalida)\n",
        "\n",
        "      pesosCapaOculta += tasaAprendizaje * np.outer(deltaSalida, salidaTotalCapaOculta[i])\n",
        "\n",
        "      for j in range(len(pesosCapaEntrada)):\n",
        "        exitacionCapaEntrada = entrada[i] @ pesosCapaEntrada[j]\n",
        "        deltaOculta = tanhDerivada(exitacionCapaEntrada) * np.dot(pesosCapaOculta.T, deltaSalida)[j]\n",
        "        pesosCapaEntrada[j] += tasaAprendizaje * entrada[i] * deltaOculta\n",
        "\n",
        "    if error < error_min:\n",
        "      error_min = error\n",
        "      w_minEntrada = pesosCapaEntrada.copy()\n",
        "      w_minOculta = pesosCapaOculta.copy()\n",
        "\n",
        "    epoca = epoca+ 1\n",
        "    if epoca % 100 == 0:\n",
        "      print(\"Epoca\", epoca, \"Error min =\", error_min)\n",
        "\n",
        "  print(\"Pesos finales capa entrada:\\n\", w_minEntrada)\n",
        "  print(\"Pesos finales capa oculta:\\n\", w_minOculta)\n",
        "\n",
        "  return w_minEntrada, w_minOculta\n",
        "\n",
        "def agregarRuido(entrada, probabilidad):\n",
        "\n",
        "    ruido = np.random.rand(len(entrada)) < probabilidad\n",
        "    entradaRuidosa = np.copy(entrada)\n",
        "    entradaRuidosa[ruido] = 1 - entradaRuidosa[ruido]\n",
        "\n",
        "    return entradaRuidosa\n",
        "\n",
        "def perceptronMuticapaPrueba(tasaAprendizaje, pesosCapaEntrada, pesosCapaOculta, entrada, salida):\n",
        "\n",
        "    pesosCapaEntrada, pesosCapaOculta = perceptronMulticapa(tasaAprendizaje, pesosCapaEntrada, pesosCapaOculta, entrada, salida)\n",
        "\n",
        "    entradasRuidosas = []\n",
        "\n",
        "    for i, entradaOriginal in enumerate(entrada):\n",
        "\n",
        "        entradaRuidosa = agregarRuido(entradaOriginal, 0.02)\n",
        "        entradasRuidosas.append(entradaRuidosa)\n",
        "\n",
        "        print(f\"Entrada {i+1} original:\\n{entradaOriginal.reshape((7,5))}\")\n",
        "        print(f\"Entrada {i+1} con ruido:\\n{entradaRuidosa.reshape((7,5))}\\n\")\n",
        "\n",
        "    print(\"\\nResultados finales de la red:\\n\")\n",
        "    print(f\"{'Entrada':>7} | {'Predicho':>35} | {'Esperado':>35} | {'Binaria':>35}\")\n",
        "    print(\"-\" * 120)\n",
        "\n",
        "    for i, entradaIndividual in enumerate(entradasRuidosas):\n",
        "\n",
        "      salidaCapaOculta = funcionTanh(np.dot(pesosCapaEntrada, entradaIndividual))\n",
        "      salidaFinal = funcionSigmoid(np.dot(pesosCapaOculta, salidaCapaOculta))\n",
        "      salidaBinaria = (salidaFinal >= 0.5).astype(int)\n",
        "\n",
        "      predicho = np.round(salidaFinal, 3)\n",
        "      esperado = salida[i]\n",
        "\n",
        "      print(f\"{i+1:>7} | {str(predicho):>35} | {str(esperado):>35} | {str(salidaBinaria):>35}\")\n",
        "\n",
        "perceptronMuticapaPrueba(0.1, pesosCapaEntrada, pesosCapaOculta, entrada, salida)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CB3X3HsgcB1y",
        "outputId": "7022ac8d-0dc9-4cbd-9132-e40909e59f5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoca 100 Error min = 0.27495801598235\n",
            "Epoca 200 Error min = 0.08558264301393005\n",
            "Epoca 300 Error min = 0.04847511256160909\n",
            "Epoca 400 Error min = 0.033287485755496254\n",
            "Epoca 500 Error min = 0.025147212500489298\n",
            "Epoca 600 Error min = 0.02011223309065742\n",
            "Epoca 700 Error min = 0.016706544296636587\n",
            "Epoca 800 Error min = 0.014257238808504057\n",
            "Epoca 900 Error min = 0.012415222465806564\n",
            "Epoca 1000 Error min = 0.010981949184093124\n",
            "Epoca 1100 Error min = 0.009836429686133987\n",
            "Epoca 1200 Error min = 0.008900861206727936\n",
            "Epoca 1300 Error min = 0.008123005417907597\n",
            "Epoca 1400 Error min = 0.0074665236235527815\n",
            "Epoca 1500 Error min = 0.006905377670940732\n",
            "Epoca 1600 Error min = 0.0064204353745120684\n",
            "Epoca 1700 Error min = 0.005997331968522178\n",
            "Epoca 1800 Error min = 0.005625077863235214\n",
            "Epoca 1900 Error min = 0.005295126114795318\n",
            "Epoca 2000 Error min = 0.005000732080895638\n",
            "Epoca 2100 Error min = 0.0047365039560174115\n",
            "Epoca 2200 Error min = 0.004498081071395702\n",
            "Epoca 2300 Error min = 0.004281899585465793\n",
            "Epoca 2400 Error min = 0.004085019120869914\n",
            "Epoca 2500 Error min = 0.0039049926568660285\n",
            "Epoca 2600 Error min = 0.0037397676126632155\n",
            "Epoca 2700 Error min = 0.003587609749889438\n",
            "Epoca 2800 Error min = 0.0034470439918509216\n",
            "Epoca 2900 Error min = 0.0033168079372995238\n",
            "Epoca 3000 Error min = 0.0031958150075912916\n",
            "Pesos finales capa entrada:\n",
            " [[-0.57185316  0.03068314 -0.17835698 ...  0.08910562 -0.28158187\n",
            "   0.49659513]\n",
            " [-0.01033461 -0.2936987  -0.17168944 ... -0.26790093  0.12374008\n",
            "   0.16760472]\n",
            " [-0.25259811  0.56984615  0.01306874 ... -0.34734992  0.1384625\n",
            "  -0.13495054]\n",
            " ...\n",
            " [-0.18669602  0.76791977 -0.04159709 ...  0.03870703 -0.49321744\n",
            "  -0.15445516]\n",
            " [-0.29124571  0.27197218  0.48183038 ...  0.41870029 -0.09821163\n",
            "   0.29593068]\n",
            " [ 0.02260156 -0.30808749  0.26709953 ...  0.7441476  -0.17717075\n",
            "   0.41106243]]\n",
            "Pesos finales capa oculta:\n",
            " [[-0.05052591 -0.97878337 -0.14766532 -0.45846956  0.56334299 -0.70207186\n",
            "   1.36018991  0.1127438   0.21792956  0.31765819  0.65681838  0.45115338\n",
            "  -0.00557778 -0.55378371 -0.08181451 -0.50378598 -0.48628703 -0.74180007\n",
            "  -0.57059385  0.67796037 -0.51190636 -0.46450815 -0.75888513  0.50036941\n",
            "   0.03361249 -0.76136325  0.86783676  1.15461714 -0.59906203  1.16442456]\n",
            " [-0.16368696 -0.18849694 -1.32582935 -0.67739924  0.96074602 -0.43358021\n",
            "  -0.01583415 -0.36736829 -0.07964707  0.02735001  0.37658553 -0.52337606\n",
            "  -0.90237557 -0.30630481 -0.09871281  0.37931782  1.00723472  0.3258261\n",
            "  -0.43069378 -0.37077279 -0.08475954  0.04547818 -0.30110884 -0.74853943\n",
            "  -0.21365001 -0.69100261  0.5893779  -0.62677167  0.59198295  0.207753  ]\n",
            " [ 0.22264205  0.15485484 -0.39814905  0.12461367  0.00829952  0.55279071\n",
            "  -0.6193371  -0.55242457  0.31488453  0.75079912  0.76653132  0.65183565\n",
            "   0.31711851 -0.74959414  1.0367013   0.25497257 -0.24672705  0.17623165\n",
            "   0.07975927 -0.13353556 -0.42499945  0.23425236 -0.3793657  -1.00709301\n",
            "  -1.41055949 -0.15925933 -0.32542726 -0.14875497  0.29739376  1.34685746]\n",
            " [-1.52250457 -0.72410133  0.31338464 -0.06285693  0.10081234  0.390564\n",
            "   0.32915793 -0.68625948  0.05105276 -0.94948453  0.12743694 -0.25653974\n",
            "  -1.00425277 -0.34606619  1.28843872 -1.1565765  -0.22280551 -0.52091567\n",
            "  -0.37159348 -0.00174333 -0.23532989 -0.28399489 -0.72984806 -0.84068218\n",
            "  -0.29743257 -0.56792169 -0.76277224  0.05720685  0.55219165 -0.53912828]\n",
            " [ 0.38234178  0.1498852  -0.91318627  0.08960354 -0.0615826   0.59268963\n",
            "   1.01795328 -0.20907103  0.56761553  0.28760552  0.53058836  1.10298039\n",
            "  -0.35038998 -0.79480479  0.14707252 -0.27876219 -0.36087062  0.20001498\n",
            "   0.32495971 -0.51465227 -0.35835539  0.15628389 -0.70498051  0.09943331\n",
            "   0.04527032 -0.34739051  0.01284006 -1.15526457 -1.04821081 -0.39759209]\n",
            " [-1.67094699 -0.65231949  0.13050282 -0.441947   -0.41349061  0.11204427\n",
            "  -0.25693509 -0.65019671  0.04401945 -0.97685714 -0.12499572 -0.31156804\n",
            "  -0.13416539 -0.84173918 -0.35593612  0.97767526  0.55537359 -0.22301431\n",
            "   0.36425711 -0.38991256 -1.00440454  0.29306827 -0.26940177  0.6408192\n",
            "  -0.6346994  -0.19270632  0.53685738 -0.24258692 -0.97414501  0.10041681]\n",
            " [-0.18610994 -0.43199536  0.0868501   0.03343625  0.06866848  0.17485869\n",
            "  -0.29303051 -0.55061329  0.18010672  0.40195522 -0.15247293 -0.07435076\n",
            "  -0.78759506 -0.29060615  0.07024275 -0.94519678  0.88661409 -1.02272465\n",
            "  -0.07229836  1.01385155 -0.46995516  1.32577184 -0.27229356 -0.15638569\n",
            "  -0.59630723 -0.6142805  -0.39903446 -1.16174776 -0.42692777  0.74691805]\n",
            " [ 0.42947717  0.17194693 -0.10640769 -0.52629141  1.28908984  0.62385267\n",
            "  -0.44979228 -0.11501996  1.6439208  -0.54716763 -0.22689942  0.06515992\n",
            "   0.33450669 -0.78350263 -0.24142034  0.33584139  0.16761786 -0.27602335\n",
            "   0.71256192 -0.420884   -0.70571449  0.68307601 -0.48863606  0.46575325\n",
            "  -0.07715405 -0.91328847 -0.88692991  0.18680383  0.45673607 -0.05516692]\n",
            " [-0.31152345  1.20489829  0.13898696  0.21514583  0.56658372 -1.58583547\n",
            "  -0.44943407 -0.77000782  0.28912686  0.67438246  0.45087033 -0.1174392\n",
            "   0.09749086 -0.67457176  1.25879824 -0.52437058 -0.71633673  0.77939703\n",
            "  -0.06390956  0.62415021 -0.68573707  0.93097017 -0.35531815  0.70498701\n",
            "  -0.45959482 -0.52592606  1.06674757  0.22084661  0.1845102  -0.6808398 ]\n",
            " [-0.10578302 -0.03347723 -0.05204928 -0.96836322  0.27024981  0.33803837\n",
            "   0.62917219 -0.16895899 -0.4092356  -1.0967019   0.57937506  0.45514814\n",
            "  -0.38519746 -0.19516179 -0.41839314 -0.32574861 -0.58031101  0.39962503\n",
            "   1.48054876  1.05603396  0.02483418 -0.1801455  -0.77212738 -0.62492505\n",
            "  -0.79875507 -0.19096039  0.95726014 -0.37517407  0.43018729 -0.00762803]]\n",
            "Entrada 1 original:\n",
            "[[0 1 1 1 0]\n",
            " [1 0 0 0 1]\n",
            " [1 0 0 1 1]\n",
            " [1 0 1 0 1]\n",
            " [1 1 0 0 1]\n",
            " [1 0 0 0 1]\n",
            " [0 1 1 1 0]]\n",
            "Entrada 1 con ruido:\n",
            "[[0 1 1 1 0]\n",
            " [1 0 0 0 1]\n",
            " [1 0 0 1 1]\n",
            " [1 0 1 0 1]\n",
            " [1 1 0 0 1]\n",
            " [1 0 0 0 1]\n",
            " [0 1 1 1 0]]\n",
            "\n",
            "Entrada 2 original:\n",
            "[[0 0 1 0 0]\n",
            " [0 1 1 0 0]\n",
            " [0 0 1 0 0]\n",
            " [0 0 1 0 0]\n",
            " [0 0 1 0 0]\n",
            " [0 0 1 0 0]\n",
            " [0 1 1 1 0]]\n",
            "Entrada 2 con ruido:\n",
            "[[0 0 1 0 0]\n",
            " [0 1 1 0 0]\n",
            " [0 0 1 0 0]\n",
            " [0 0 1 0 0]\n",
            " [0 0 1 0 1]\n",
            " [0 0 1 0 0]\n",
            " [0 1 1 1 0]]\n",
            "\n",
            "Entrada 3 original:\n",
            "[[0 1 1 1 0]\n",
            " [1 0 0 0 1]\n",
            " [0 0 0 0 1]\n",
            " [0 0 0 1 0]\n",
            " [0 0 1 0 0]\n",
            " [0 1 0 0 0]\n",
            " [1 1 1 1 1]]\n",
            "Entrada 3 con ruido:\n",
            "[[0 1 1 1 0]\n",
            " [1 0 0 0 1]\n",
            " [1 0 0 0 1]\n",
            " [0 0 0 1 0]\n",
            " [0 0 1 0 0]\n",
            " [0 1 0 0 0]\n",
            " [1 1 1 1 1]]\n",
            "\n",
            "Entrada 4 original:\n",
            "[[0 1 1 1 0]\n",
            " [1 0 0 0 1]\n",
            " [0 0 0 0 1]\n",
            " [0 0 1 1 0]\n",
            " [0 0 0 0 1]\n",
            " [1 0 0 0 1]\n",
            " [0 1 1 1 0]]\n",
            "Entrada 4 con ruido:\n",
            "[[0 1 1 1 0]\n",
            " [1 0 0 0 1]\n",
            " [0 0 0 0 1]\n",
            " [0 0 1 1 0]\n",
            " [0 0 0 0 1]\n",
            " [1 0 0 0 1]\n",
            " [0 0 1 1 0]]\n",
            "\n",
            "Entrada 5 original:\n",
            "[[0 0 0 1 0]\n",
            " [0 0 1 1 0]\n",
            " [0 1 0 1 0]\n",
            " [1 0 0 1 0]\n",
            " [1 1 1 1 1]\n",
            " [0 0 0 1 0]\n",
            " [0 0 0 1 0]]\n",
            "Entrada 5 con ruido:\n",
            "[[0 0 1 1 0]\n",
            " [0 0 1 1 0]\n",
            " [0 1 1 1 0]\n",
            " [1 0 0 1 0]\n",
            " [1 1 1 1 0]\n",
            " [0 0 0 1 0]\n",
            " [0 0 0 1 0]]\n",
            "\n",
            "Entrada 6 original:\n",
            "[[1 1 1 1 1]\n",
            " [1 0 0 0 0]\n",
            " [1 1 1 1 0]\n",
            " [0 0 0 0 1]\n",
            " [0 0 0 0 1]\n",
            " [1 0 0 0 1]\n",
            " [0 1 1 1 0]]\n",
            "Entrada 6 con ruido:\n",
            "[[1 0 0 1 1]\n",
            " [1 0 0 0 0]\n",
            " [1 1 1 1 0]\n",
            " [0 0 0 0 1]\n",
            " [0 0 0 0 1]\n",
            " [1 0 0 0 1]\n",
            " [0 1 1 1 0]]\n",
            "\n",
            "Entrada 7 original:\n",
            "[[0 0 1 1 0]\n",
            " [0 1 0 0 0]\n",
            " [1 0 0 0 0]\n",
            " [1 1 1 1 0]\n",
            " [1 0 0 0 1]\n",
            " [1 0 0 0 1]\n",
            " [0 1 1 1 0]]\n",
            "Entrada 7 con ruido:\n",
            "[[0 0 1 1 0]\n",
            " [0 1 0 0 0]\n",
            " [1 0 0 0 0]\n",
            " [1 1 1 1 0]\n",
            " [0 0 0 0 1]\n",
            " [1 0 0 0 0]\n",
            " [0 1 1 1 0]]\n",
            "\n",
            "Entrada 8 original:\n",
            "[[1 1 1 1 1]\n",
            " [0 0 0 0 1]\n",
            " [0 0 0 1 0]\n",
            " [0 0 1 0 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]]\n",
            "Entrada 8 con ruido:\n",
            "[[1 1 1 1 1]\n",
            " [0 0 0 0 1]\n",
            " [0 0 0 1 0]\n",
            " [0 0 1 0 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]]\n",
            "\n",
            "Entrada 9 original:\n",
            "[[0 1 1 1 0]\n",
            " [1 0 0 0 1]\n",
            " [1 0 0 0 1]\n",
            " [0 1 1 1 0]\n",
            " [1 0 0 0 1]\n",
            " [1 0 0 0 1]\n",
            " [0 1 1 1 0]]\n",
            "Entrada 9 con ruido:\n",
            "[[0 1 0 1 0]\n",
            " [1 0 0 0 1]\n",
            " [1 0 0 0 1]\n",
            " [0 1 1 1 0]\n",
            " [1 0 0 0 1]\n",
            " [1 1 0 0 1]\n",
            " [0 1 1 1 0]]\n",
            "\n",
            "Entrada 10 original:\n",
            "[[0 1 1 1 0]\n",
            " [1 0 0 0 1]\n",
            " [1 0 0 0 1]\n",
            " [0 1 1 1 1]\n",
            " [0 0 0 0 1]\n",
            " [0 0 0 1 0]\n",
            " [0 1 1 0 0]]\n",
            "Entrada 10 con ruido:\n",
            "[[0 1 1 1 0]\n",
            " [1 0 0 0 1]\n",
            " [1 0 0 0 1]\n",
            " [0 1 1 1 1]\n",
            " [0 0 0 0 1]\n",
            " [0 0 0 1 0]\n",
            " [0 1 1 0 0]]\n",
            "\n",
            "\n",
            "Resultados finales de la red:\n",
            "\n",
            "Entrada |                            Predicho |                            Esperado |                             Binaria\n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "      1 | [0.983 0.001 0.001 0.001 0.009 0.008 0.011 0.    0.01  0.008] |     [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.] |               [1 0 0 0 0 0 0 0 0 0]\n",
            "      2 | [0.001 0.961 0.007 0.007 0.01  0.009 0.009 0.003 0.005 0.007] |     [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.] |               [0 1 0 0 0 0 0 0 0 0]\n",
            "      3 | [0.003 0.005 0.964 0.002 0.006 0.001 0.001 0.008 0.008 0.016] |     [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.] |               [0 0 1 0 0 0 0 0 0 0]\n",
            "      4 | [0.004 0.005 0.005 0.986 0.001 0.016 0.021 0.002 0.022 0.004] |     [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.] |               [0 0 0 1 0 0 0 0 0 0]\n",
            "      5 | [0.011 0.014 0.008 0.001 0.97  0.004 0.003 0.011 0.001 0.002] |     [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.] |               [0 0 0 0 1 0 0 0 0 0]\n",
            "      6 | [0.017 0.01  0.    0.02  0.005 0.99  0.005 0.011 0.001 0.019] |     [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.] |               [0 0 0 0 0 1 0 0 0 0]\n",
            "      7 | [0.002 0.037 0.014 0.035 0.006 0.004 0.957 0.006 0.001 0.007] |     [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.] |               [0 0 0 0 0 0 1 0 0 0]\n",
            "      8 | [0.001 0.008 0.007 0.004 0.008 0.01  0.    0.985 0.005 0.009] |     [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.] |               [0 0 0 0 0 0 0 1 0 0]\n",
            "      9 | [0.004 0.001 0.009 0.004 0.002 0.    0.006 0.002 0.974 0.005] |     [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.] |               [0 0 0 0 0 0 0 0 1 0]\n",
            "     10 | [0.01  0.003 0.008 0.007 0.005 0.006 0.    0.01  0.01  0.986] |     [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.] |               [0 0 0 0 0 0 0 0 0 1]\n"
          ]
        }
      ]
    }
  ]
}